{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from num2words import num2words\n",
    "def goal_translate(goals):\n",
    "    goal_trans = ''\n",
    "    sub_goal = ''\n",
    "    for goal in goals:\n",
    "        act = re.findall(r'\\w+\\b', goal)\n",
    "        #print(act)\n",
    "        if len(act)==2:\n",
    "            sub_goal = '{} the {}'.format(act[0],act[1])\n",
    "        if len(act)==4:\n",
    "            sub_goal = 'put {} {} {} {}'.format(num2words(act[3]),act[1], act[0], act[2])\n",
    "        goal_trans = goal_trans + sub_goal + ', '\n",
    "    goal_trans = goal_trans.lower()\n",
    "    goal_trans = goal_trans[:-2] + '.'\n",
    "    return goal_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INSIDE', 'cutleryfork', 'dishwasher', '3']\n",
      "['ON', 'wineglass', 'sink', '2']\n",
      "['INSIDE', 'waterglass', 'dishwasher', '1']\n",
      "['CLOSE', 'dishwasher']\n",
      "['TURNON', 'dishwasher']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'put three cutleryfork inside dishwasher, put two wineglass on sink, put one waterglass inside dishwasher, close the dishwasher, turnon the dishwasher.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goals = ['INSIDE (cutleryfork, dishwasher): 3','ON (wineglass, sink): 2','INSIDE (waterglass, dishwasher): 1',\n",
    "         'CLOSE (dishwasher)','TURNON (dishwasher)']\n",
    "goal_translate(goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  40,  423,  257, 4320]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n",
      "[[[-0.07962783 -0.06535359 -0.08424436 ... -0.14416133 -0.04557567\n",
      "    0.01425   ]\n",
      "  [-0.19016495 -0.17212972 -0.79750437 ... -0.17365916  0.6244487\n",
      "    0.30738056]\n",
      "  [ 0.03623195  0.12202189 -0.21445212 ... -0.38196504  0.34530863\n",
      "    0.07974897]\n",
      "  [-0.1296617  -0.6143206  -1.5262644  ... -0.22204967  0.13208918\n",
      "    0.08905733]]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import tensorflow as tf\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"I have a dream\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(encoded_input)\n",
    "output = model(**encoded_input)\n",
    "print(output.last_hidden_state.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2Model' object has no attribute 'transformer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18380/3996476722.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGPT2Model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'gpt2'\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# or any other checkpoint\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mword_embeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransformer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwte\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m  \u001B[1;31m# Word Token Embeddings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mposition_embeddings\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransformer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwpe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m  \u001B[1;31m# Word Position Embeddings\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1175\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodules\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1176\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mmodules\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1177\u001B[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001B[0m\u001B[0;32m   1178\u001B[0m             type(self).__name__, name))\n\u001B[0;32m   1179\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'GPT2Model' object has no attribute 'transformer'"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')  # or any other checkpoint\n",
    "word_embeddings = model.transformer.wte.weight  # Word Token Embeddings\n",
    "position_embeddings = model.transformer.wpe.weight  # Word Position Embeddings\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "text_index = tokenizer.encode('I have a dream')\n",
    "print(text_index)\n",
    "vector = word_embeddings[text_index,:]\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.gpt2.modeling_tf_gpt2 because of the following error (look up to see its traceback):\nDLL load failed while importing defs: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36m_get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   2776\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2777\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\".\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmodule_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2778\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 127\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    128\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_tf_gpt2.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m )\n\u001B[1;32m---> 37\u001B[1;33m from ...modeling_tf_utils import (\n\u001B[0m\u001B[0;32m     38\u001B[0m     \u001B[0mTFCausalLanguageModelingLoss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mh5py\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\h5py\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 33\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mversion\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\h5py\\version.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mcollections\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnamedtuple\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mh5\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_h5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mh5py\\h5.pyx\u001B[0m in \u001B[0;36minit h5py.h5\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing defs: The specified procedure could not be found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18380/2027101265.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtransformers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mgenerator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'text-generation'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'gpt2'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mgenerator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"kitchencabinet\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m30\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_return_sequences\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001B[0m in \u001B[0;36mpipeline\u001B[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[0;32m    547\u001B[0m     \u001B[1;31m# Will load the correct model if possible\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    548\u001B[0m     \u001B[0mmodel_classes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"tf\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtargeted_task\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"tf\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"pt\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtargeted_task\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"pt\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 549\u001B[1;33m     framework, model = infer_framework_load_model(\n\u001B[0m\u001B[0;32m    550\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    551\u001B[0m         \u001B[0mmodel_classes\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001B[0m in \u001B[0;36minfer_framework_load_model\u001B[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001B[0m\n\u001B[0;32m    221\u001B[0m                         \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_class\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mlook_tf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m                     \u001B[0m_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtransformers_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf\"TF{architecture}\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0m_class\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m                         \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_class\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   2766\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_class_to_module\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2767\u001B[0m             \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_class_to_module\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2768\u001B[1;33m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2769\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2770\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"module {self.__name__} has no attribute {name}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   2765\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2766\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_class_to_module\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2767\u001B[1;33m             \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_class_to_module\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2768\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2769\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\app\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001B[0m in \u001B[0;36m_get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   2777\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\".\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmodule_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2778\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2779\u001B[1;33m             raise RuntimeError(\n\u001B[0m\u001B[0;32m   2780\u001B[0m                 \u001B[1;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its traceback):\\n{e}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2781\u001B[0m             ) from e\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.models.gpt2.modeling_tf_gpt2 because of the following error (look up to see its traceback):\nDLL load failed while importing defs: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "generator(\"kitchencabinet\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0796, -0.0654, -0.0842,  ..., -0.1442, -0.0456,  0.0142],\n",
       "        [-0.1902, -0.1721, -0.7975,  ..., -0.1737,  0.6244,  0.3074],\n",
       "        [ 0.0362,  0.1220, -0.2145,  ..., -0.3820,  0.3453,  0.0797],\n",
       "        [-0.1297, -0.6143, -1.5263,  ..., -0.2220,  0.1321,  0.0891]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch as tc\n",
    "modelGPT = GPT2Model.from_pretrained('gpt2')\n",
    "modelGPT(inputs_embeds=tc.FloatTensor(vector.detach().numpy())).last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create word embeddings and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, ReLU, Concatenate, Lambda\n",
    "import numpy as np\n",
    "\n",
    "def get_word_embeddings(lm):\n",
    "    model = GPT2LMHeadModel.from_pretrained(lm)\n",
    "    word_embeddings = model.transformer.wte.weight\n",
    "    return word_embeddings\n",
    "\n",
    "def get_tokenizer(lm):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(lm)\n",
    "    return tokenizer\n",
    "\n",
    "gpt2_word_embeddings = get_word_embeddings('gpt2')\n",
    "gpt2_tokenizer = get_tokenizer('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_goal_embeddings(word_embeddings, tokenizer, goal):\n",
    "    goal_token = tokenizer.encode(goal)\n",
    "    goal_embeddings = word_embeddings[goal_token,:].detach().numpy()\n",
    "    return goal_embeddings\n",
    "\n",
    "gpt2_goal_embeddings = get_goal_embeddings(gpt2_word_embeddings, gpt2_tokenizer, 'put one apple on the table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_history_embeddings(word_embeddings, tokenizer, history):\n",
    "    history_token = tokenizer.encode(history)\n",
    "    history_embeddings = word_embeddings[history_token,:].detach().numpy()\n",
    "    return history_embeddings\n",
    "\n",
    "gpt2_history_embeddings = get_history_embeddings(gpt2_word_embeddings, gpt2_tokenizer, 'I have walked to the kitchen, grabbed the apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)          [(None, 1, 6)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 1, 64)        448         ['input_33[0][0]']               \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)          [(None, 1, 768)]     0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 1, 6)]       0           []                               \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 1, 64)        0           ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)              (None, 1, 768)       0           ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 1, 64)        448         ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 1, 64)        4160        ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 1, 896)       0           ['lambda_9[0][0]',               \n",
      "                                                                  'dense_54[0][0]',               \n",
      "                                                                  'dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 1, 768)       688896      ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 693,952\n",
      "Trainable params: 693,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embed name\n",
    "def get_name_embeddings(name):\n",
    "    name_token = gpt2_tokenizer.encode(name)\n",
    "    name_embeddings = gpt2_word_embeddings[name_token,:].detach().numpy()\n",
    "    name_embeddings = np.mean(name_embeddings, axis=0)\n",
    "    return name_embeddings\n",
    "\n",
    "gpt2_name_embeddings = get_name_embeddings('kitchen oven')\n",
    "\n",
    "def get_state_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=6))\n",
    "    return model\n",
    "\n",
    "gpt2_state_model = get_state_model()\n",
    "gpt2_state_embeddings = gpt2_state_model.predict(np.array([[1, 0, 0, 1, 0, 0]]))\n",
    "\n",
    "def get_position_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=6))\n",
    "    model.add(ReLU)\n",
    "    model.add(Dense(64))\n",
    "    return model\n",
    "\n",
    "gpt2_position_model = get_state_model()\n",
    "gpt2_position_embeddings = gpt2_position_model.predict(np.array([[0.4, 0.2, 0.4, 0.1, 0.02, 0.03]]))\n",
    "\n",
    "def get_object_model(word_embeddings, tokenizer, state_model, position_model, name, state, position):\n",
    "    name_token = tokenizer.encode(name)\n",
    "    name_embeddings = word_embeddings[name_token,:].detach().numpy()\n",
    "    name_embeddings = np.mean(name_embeddings, axis=0)\n",
    "\n",
    "    state_embeddings = state_model.predict(state)\n",
    "\n",
    "    position_embeddings = position_model.predict(position)\n",
    "\n",
    "    merged = np.concatenate([name_embeddings, state_embeddings, position_embeddings])\n",
    "\n",
    "    merged = Dense(768)(merged)\n",
    "\n",
    "    input = Input(shape=(864, 1))\n",
    "    model = Model(input, merged)\n",
    "    return model\n",
    "\n",
    "def get_object_model_new():\n",
    "    name_input = Input(shape=(1, 768))\n",
    "    state_input = Input(shape=(1, 6))\n",
    "    position_input = Input(shape=(1, 6))\n",
    "\n",
    "    name_embeddings = Lambda(lambda x: x)(name_input)\n",
    "\n",
    "    state_embeddings = Dense(64)(state_input)\n",
    "\n",
    "    position_embeddings = Dense(64)(position_input)\n",
    "    position_embeddings = ReLU()(position_embeddings)\n",
    "    position_embeddings = Dense(64)(position_embeddings)\n",
    "\n",
    "    merged = Concatenate()([name_embeddings, state_embeddings, position_embeddings])\n",
    "    merged = Dense(768)(merged)\n",
    "\n",
    "    model = Model([name_input, state_input, position_input], merged)\n",
    "    return model\n",
    "\n",
    "object_model = get_object_model_new()\n",
    "print(object_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}